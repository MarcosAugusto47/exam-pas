{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7301, 23)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = pd.read_parquet('../data/scores.parquet')\n",
    "approvals = pd.read_parquet('../data/approvals.parquet')\n",
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = scores[~scores.course.str.contains('JUDICE')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numero_inscricao</th>\n",
       "      <th>nome</th>\n",
       "      <th>escore_bruto_p1_etapa1</th>\n",
       "      <th>escore_bruto_p2_etapa1</th>\n",
       "      <th>nota_redacao_etapa1</th>\n",
       "      <th>escore_bruto_p1_etapa2</th>\n",
       "      <th>escore_bruto_p2_etapa2</th>\n",
       "      <th>nota_redacao_etapa2</th>\n",
       "      <th>escore_bruto_p1_etapa3</th>\n",
       "      <th>escore_bruto_p2_etapa3</th>\n",
       "      <th>...</th>\n",
       "      <th>classificacao_final_cotas_negros</th>\n",
       "      <th>classificacao_final_publicas1</th>\n",
       "      <th>classificacao_final_publicas2</th>\n",
       "      <th>classificacao_final_publicas3</th>\n",
       "      <th>classificacao_final_publicas4</th>\n",
       "      <th>classificacao_final_publicas5</th>\n",
       "      <th>classificacao_final_publicas6</th>\n",
       "      <th>classificacao_final_publicas7</th>\n",
       "      <th>classificacao_final_publicas8</th>\n",
       "      <th>course</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20199023</td>\n",
       "      <td>Amanda Amorim Luz</td>\n",
       "      <td>5.172</td>\n",
       "      <td>14.653</td>\n",
       "      <td>6.947</td>\n",
       "      <td>3.845</td>\n",
       "      <td>19.994</td>\n",
       "      <td>7.222</td>\n",
       "      <td>4.998</td>\n",
       "      <td>16.660</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2.1.1 CAMPUS  DARCY RIBEIRO – DIURNO  ADMINIST...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20180980</td>\n",
       "      <td>Amanda Larissa Oliveira dos Santos</td>\n",
       "      <td>6.896</td>\n",
       "      <td>48.271</td>\n",
       "      <td>3.800</td>\n",
       "      <td>6.152</td>\n",
       "      <td>54.342</td>\n",
       "      <td>7.200</td>\n",
       "      <td>5.712</td>\n",
       "      <td>46.648</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2.1.1 CAMPUS  DARCY RIBEIRO – DIURNO  ADMINIST...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20188220</td>\n",
       "      <td>Amanda Luisa de Oliveira Souza</td>\n",
       "      <td>0.000</td>\n",
       "      <td>23.704</td>\n",
       "      <td>5.333</td>\n",
       "      <td>0.769</td>\n",
       "      <td>24.303</td>\n",
       "      <td>6.909</td>\n",
       "      <td>2.142</td>\n",
       "      <td>25.465</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2.1.1 CAMPUS  DARCY RIBEIRO – DIURNO  ADMINIST...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20193280</td>\n",
       "      <td>Amanda Mendes Reis de Araujo</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10.342</td>\n",
       "      <td>8.963</td>\n",
       "      <td>2.307</td>\n",
       "      <td>14.866</td>\n",
       "      <td>9.5 86</td>\n",
       "      <td>1.428</td>\n",
       "      <td>13.088</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2.1.1 CAMPUS  DARCY RIBEIRO – DIURNO  ADMINIST...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20188170</td>\n",
       "      <td>Ana Beatriz Cattermol Cavalcante</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10.917</td>\n",
       "      <td>2.848</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10.764</td>\n",
       "      <td>3.750</td>\n",
       "      <td>6.426</td>\n",
       "      <td>17.373</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2.1.1 CAMPUS  DARCY RIBEIRO – DIURNO  ADMINIST...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  numero_inscricao                                nome escore_bruto_p1_etapa1  \\\n",
       "0         20199023                   Amanda Amorim Luz                  5.172   \n",
       "1         20180980  Amanda Larissa Oliveira dos Santos                  6.896   \n",
       "2         20188220      Amanda Luisa de Oliveira Souza                  0.000   \n",
       "3         20193280        Amanda Mendes Reis de Araujo                  0.000   \n",
       "4         20188170    Ana Beatriz Cattermol Cavalcante                  0.000   \n",
       "\n",
       "  escore_bruto_p2_etapa1 nota_redacao_etapa1 escore_bruto_p1_etapa2  \\\n",
       "0                 14.653               6.947                  3.845   \n",
       "1                 48.271               3.800                  6.152   \n",
       "2                 23.704               5.333                  0.769   \n",
       "3                 10.342               8.963                  2.307   \n",
       "4                 10.917               2.848                  0.000   \n",
       "\n",
       "  escore_bruto_p2_etapa2 nota_redacao_etapa2 escore_bruto_p1_etapa3  \\\n",
       "0                 19.994               7.222                  4.998   \n",
       "1                 54.342               7.200                  5.712   \n",
       "2                 24.303               6.909                  2.142   \n",
       "3                 14.866              9.5 86                  1.428   \n",
       "4                 10.764               3.750                  6.426   \n",
       "\n",
       "  escore_bruto_p2_etapa3  ... classificacao_final_cotas_negros  \\\n",
       "0                 16.660  ...                             None   \n",
       "1                 46.648  ...                             None   \n",
       "2                 25.465  ...                             None   \n",
       "3                 13.088  ...                             None   \n",
       "4                 17.373  ...                                1   \n",
       "\n",
       "  classificacao_final_publicas1 classificacao_final_publicas2  \\\n",
       "0                          None                           NaN   \n",
       "1                          None                           NaN   \n",
       "2                          None                           NaN   \n",
       "3                          None                           NaN   \n",
       "4                          None                           NaN   \n",
       "\n",
       "  classificacao_final_publicas3 classificacao_final_publicas4  \\\n",
       "0                          None                          None   \n",
       "1                          None                          None   \n",
       "2                          None                          None   \n",
       "3                          None                          None   \n",
       "4                          None                          None   \n",
       "\n",
       "   classificacao_final_publicas5 classificacao_final_publicas6  \\\n",
       "0                           None                           NaN   \n",
       "1                           None                           NaN   \n",
       "2                           None                           NaN   \n",
       "3                           None                           NaN   \n",
       "4                           None                           NaN   \n",
       "\n",
       "  classificacao_final_publicas7 classificacao_final_publicas8  \\\n",
       "0                          None                          None   \n",
       "1                          None                          None   \n",
       "2                          None                          None   \n",
       "3                          None                          None   \n",
       "4                          None                          None   \n",
       "\n",
       "                                              course  \n",
       "0  2.1.1 CAMPUS  DARCY RIBEIRO – DIURNO  ADMINIST...  \n",
       "1  2.1.1 CAMPUS  DARCY RIBEIRO – DIURNO  ADMINIST...  \n",
       "2  2.1.1 CAMPUS  DARCY RIBEIRO – DIURNO  ADMINIST...  \n",
       "3  2.1.1 CAMPUS  DARCY RIBEIRO – DIURNO  ADMINIST...  \n",
       "4  2.1.1 CAMPUS  DARCY RIBEIRO – DIURNO  ADMINIST...  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['classificacao_final_cotas_negros',\n",
       " 'classificacao_final_publicas1',\n",
       " 'classificacao_final_publicas2',\n",
       " 'classificacao_final_publicas3',\n",
       " 'classificacao_final_publicas4',\n",
       " 'classificacao_final_publicas5',\n",
       " 'classificacao_final_publicas6',\n",
       " 'classificacao_final_publicas7',\n",
       " 'classificacao_final_publicas8']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cotas_columns = [col for col in scores.columns if 'classificacao' in col]\n",
    "cotas_columns.pop(0) # removing 'classificacao_final_universal'\n",
    "cotas_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores['cotista'] = scores[cotas_columns].notnull().any(axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in cotas_columns:\n",
    "    scores[f'{column}_flag'] = scores[column].notnull().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags_columns = list(scores.columns[scores.columns.str.contains('flag')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(scores, approvals, how='left', on='numero_inscricao', indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df._merge.apply(lambda x: 1 if x == 'both' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = ['escore_bruto_p1_etapa1',\n",
    "            'escore_bruto_p2_etapa1',\n",
    "            'nota_redacao_etapa1',\n",
    "            'escore_bruto_p1_etapa2',\n",
    "            'escore_bruto_p2_etapa2',\n",
    "            'nota_redacao_etapa2',\n",
    "            'escore_bruto_p1_etapa3',\n",
    "            'escore_bruto_p2_etapa3',\n",
    "            'nota_redacao_etapa3',\n",
    "            'argumento_final']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_string_to_float(df, colnames):\n",
    "    for colname in colnames:\n",
    "        df[colname] = df[colname].str.replace(' ', \"\", regex=True)\n",
    "        df[colname] = df[colname].str.replace('[R$]', \"\", regex=True)\n",
    "        df[colname] = df[colname].str.replace(',', \".\", regex=False)\n",
    "        df[colname] = df[colname].apply(float)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = convert_string_to_float(df, FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_dummies = pd.get_dummies(df.course)\n",
    "course_dummies_columns = list(course_dummies.columns)\n",
    "df = pd.concat([df, course_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES.extend(course_dummies_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(FEATURES)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[FEATURES] # features\n",
    "y = df['label'] # labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=47) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8492773571920165\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.8618944323933478,\n",
       "  'recall': 0.9770491803278688,\n",
       "  'f1-score': 0.9158663081060315,\n",
       "  'support': 1220},\n",
       " '1': {'precision': 0.6,\n",
       "  'recall': 0.18025751072961374,\n",
       "  'f1-score': 0.27722772277227725,\n",
       "  'support': 233},\n",
       " 'accuracy': 0.8492773571920165,\n",
       " 'macro avg': {'precision': 0.7309472161966739,\n",
       "  'recall': 0.5786533455287413,\n",
       "  'f1-score': 0.5965470154391543,\n",
       "  'support': 1453},\n",
       " 'weighted avg': {'precision': 0.8198975963660595,\n",
       "  'recall': 0.8492773571920165,\n",
       "  'f1-score': 0.8134555783174804,\n",
       "  'support': 1453}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Random Forest Classifier\n",
    "model = RandomForestClassifier(random_state=47)\n",
    "\n",
    "# Fit randomized search\n",
    "model = model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print('Accuracy:', metrics.accuracy_score(y_test, y_pred))\n",
    "classification_report(y_test, y_pred, output_dict=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model + cotista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES.append('cotista')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[FEATURES] # features\n",
    "y = df['label'] # labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=47) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8582243633860978\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.868995633187773,\n",
       "  'recall': 0.978688524590164,\n",
       "  'f1-score': 0.920585967617579,\n",
       "  'support': 1220},\n",
       " '1': {'precision': 0.6708860759493671,\n",
       "  'recall': 0.22746781115879827,\n",
       "  'f1-score': 0.33974358974358976,\n",
       "  'support': 233},\n",
       " 'accuracy': 0.8582243633860978,\n",
       " 'macro avg': {'precision': 0.76994085456857,\n",
       "  'recall': 0.6030781678744811,\n",
       "  'f1-score': 0.6301647786805844,\n",
       "  'support': 1453},\n",
       " 'weighted avg': {'precision': 0.8372272045321992,\n",
       "  'recall': 0.8582243633860978,\n",
       "  'f1-score': 0.8274433151436358,\n",
       "  'support': 1453}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Random Forest Classifier\n",
    "model = RandomForestClassifier(random_state=47)\n",
    "\n",
    "# Fit randomized search\n",
    "model = model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print('Accuracy:', metrics.accuracy_score(y_test, y_pred))\n",
    "classification_report(y_test, y_pred, output_dict=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model + Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEATURES.extend(flags_columns)\n",
    "len(FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[FEATURES] # features\n",
    "y = df['label'] # labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=47) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.8802045288531775,\n",
       "  'recall': 0.9877049180327869,\n",
       "  'f1-score': 0.9308613364233295,\n",
       "  'support': 1220},\n",
       " '1': {'precision': 0.8214285714285714,\n",
       "  'recall': 0.296137339055794,\n",
       "  'f1-score': 0.4353312302839117,\n",
       "  'support': 233},\n",
       " 'accuracy': 0.8768066070199587,\n",
       " 'macro avg': {'precision': 0.8508165501408744,\n",
       "  'recall': 0.6419211285442905,\n",
       "  'f1-score': 0.6830962833536206,\n",
       "  'support': 1453},\n",
       " 'weighted avg': {'precision': 0.8707793409110348,\n",
       "  'recall': 0.8768066070199587,\n",
       "  'f1-score': 0.8513991790038633,\n",
       "  'support': 1453}}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Random Forest Classifier\n",
    "model = RandomForestClassifier(random_state=47)\n",
    "\n",
    "# Fit randomized search\n",
    "model = model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "classification_report(y_test, y_pred, output_dict=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning + class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RandomForestClassifierGridSearch import RandomForestClassifierGridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 500],      # Number of trees in the forest\n",
    "    'max_depth': [5, 10, 20, 40, 60],            # Maximum depth of each tree\n",
    "    'min_samples_split': [5, 10, 20, 40, 60],       # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [2, 8, 16, 32]          # Minimum number of samples required to be at a leaf node\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomForestClassifierGridSearch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\MARCOS~1\\AppData\\Local\\Temp/ipykernel_8376/473772764.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Instantiate the class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mrf_gs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifierGridSearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Fit the classifier using GridSearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RandomForestClassifierGridSearch' is not defined"
     ]
    }
   ],
   "source": [
    "# Assuming you have your training data X_train and corresponding labels y_train\n",
    "\n",
    "# Instantiate the class\n",
    "rf_gs = RandomForestClassifierGridSearch(X_train, y_train)\n",
    "\n",
    "# Fit the classifier using GridSearchCV\n",
    "rf_gs.fit(param_grid)\n",
    "\n",
    "# Assuming you have your test data X_test and corresponding labels y_test\n",
    "\n",
    "# Evaluate the best model on the test data\n",
    "report = rf_gs.evaluate(X_test, y_test)\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_flags_tuned.pickle','wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('model_flags_tuned.pickle','wb') as f:\n",
    "#  pickle.dump(model, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified KFold + Hyperameter tuning + Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],      # Number of trees in the forest\n",
    "    'max_depth': [5, 10, 20, 40, 80],            # Maximum depth of each tree\n",
    "    'min_samples_split': [5, 10, 20, 50],       # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [2, 8, 16, 32],          # Minimum number of samples required to be at a leaf node\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5810, 111)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92      1220\n",
      "           1       0.59      0.59      0.59       233\n",
      "\n",
      "    accuracy                           0.87      1453\n",
      "   macro avg       0.76      0.76      0.76      1453\n",
      "weighted avg       0.87      0.87      0.87      1453\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have your training data X_train and corresponding labels y_train\n",
    "\n",
    "# Instantiate the class\n",
    "rf_gs = RandomForestClassifierGridSearch(X_train, y_train)\n",
    "\n",
    "# Fit the classifier using GridSearchCV\n",
    "rf_gs.fit(param_grid)\n",
    "\n",
    "# Assuming you have your test data X_test and corresponding labels y_test\n",
    "\n",
    "# Evaluate the best model on the test data\n",
    "report = rf_gs.evaluate(X_test, y_test)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_gs.save_model('stratified_kfold_classweight15_tuned_model.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stratified_kfold_classweight15_tuned_model.pickle.pickle', 'rb') as f:\n",
    "  loaded_pipe = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.9220672682526662,\n",
       "  'recall': 0.921311475409836,\n",
       "  'f1-score': 0.921689216892169,\n",
       "  'support': 1220},\n",
       " '1': {'precision': 0.5897435897435898,\n",
       "  'recall': 0.592274678111588,\n",
       "  'f1-score': 0.5910064239828693,\n",
       "  'support': 233},\n",
       " 'accuracy': 0.868547832071576,\n",
       " 'macro avg': {'precision': 0.755905428998128,\n",
       "  'recall': 0.7567930767607121,\n",
       "  'f1-score': 0.7563478204375191,\n",
       "  'support': 1453},\n",
       " 'weighted avg': {'precision': 0.8687765476108115,\n",
       "  'recall': 0.868547832071576,\n",
       "  'f1-score': 0.8686616251868237,\n",
       "  'support': 1453}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = loaded_pipe.predict(X_test)\n",
    "classification_report(y_test, y_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.9222042139384117,\n",
       "  'recall': 0.9327868852459016,\n",
       "  'f1-score': 0.9274653626731867,\n",
       "  'support': 1220},\n",
       " '1': {'precision': 0.6255707762557078,\n",
       "  'recall': 0.5879828326180258,\n",
       "  'f1-score': 0.6061946902654868,\n",
       "  'support': 233},\n",
       " 'accuracy': 0.8774948382656572,\n",
       " 'macro avg': {'precision': 0.7738874950970598,\n",
       "  'recall': 0.7603848589319637,\n",
       "  'f1-score': 0.7668300264693367,\n",
       "  'support': 1453},\n",
       " 'weighted avg': {'precision': 0.8746367046610064,\n",
       "  'recall': 0.8774948382656572,\n",
       "  'f1-score': 0.8759470786601143,\n",
       "  'support': 1453}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = loaded_pipe.predict(X_test)\n",
    "classification_report(y_test, y_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
